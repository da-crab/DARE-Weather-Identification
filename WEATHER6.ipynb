{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12623 images belonging to 5 classes.\n",
      "Found 2705 images belonging to 5 classes.\n",
      "Found 2710 images belonging to 5 classes.\n",
      "\n",
      "######################################################################\n",
      "### PROCESSING RUN 1/5\n",
      "######################################################################\n",
      "\n",
      "============================================================\n",
      "=== Training Custom_CNN for Run 1 ===\n",
      "============================================================\n",
      "Loading existing model from: saved_models\\Custom_CNN.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Boome\\anaconda3\\envs\\myTF\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - acc: 0.7139 - loss: 0.7534 - val_acc: 0.7486 - val_loss: 0.6955\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - acc: 0.7309 - loss: 0.7135 - val_acc: 0.7368 - val_loss: 0.6846\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - acc: 0.7349 - loss: 0.6998 - val_acc: 0.7268 - val_loss: 0.7139\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - acc: 0.7480 - loss: 0.6692 - val_acc: 0.7564 - val_loss: 0.6580\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - acc: 0.7472 - loss: 0.6602 - val_acc: 0.7590 - val_loss: 0.6478\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - acc: 0.7481 - loss: 0.6663 - val_acc: 0.7512 - val_loss: 0.6868\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 1s/step - acc: 0.7651 - loss: 0.6291 - val_acc: 0.7675 - val_loss: 0.6084\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - acc: 0.7620 - loss: 0.6295 - val_acc: 0.7534 - val_loss: 0.6786\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - acc: 0.7676 - loss: 0.6208 - val_acc: 0.6906 - val_loss: 0.8692\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - acc: 0.7675 - loss: 0.6136 - val_acc: 0.7287 - val_loss: 0.7485\n",
      "Epoch 11/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - acc: 0.7792 - loss: 0.6007 - val_acc: 0.7549 - val_loss: 0.6436\n",
      "Epoch 12/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 2s/step - acc: 0.7812 - loss: 0.5741 - val_acc: 0.7641 - val_loss: 0.6272\n",
      "Epoch 13/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - acc: 0.7791 - loss: 0.5900 - val_acc: 0.7405 - val_loss: 0.6697\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Saving model to: saved_models\\Custom_CNN.keras\n",
      "Training history plot saved to results\\Custom_CNN\\Run_1\\training_history.png\n",
      "\n",
      "--- Performing quick test evaluation ---\n",
      "--> Test Accuracy: 76.75%\n",
      "--- Generating individual report and saving results to: results\\Custom_CNN\\Run_1 ---\n",
      "Individual classification report saved to results\\Custom_CNN\\Run_1\\classification_report.txt\n",
      "Individual confusion matrix plot saved to results\\Custom_CNN\\Run_1\\confusion_matrix.png\n",
      "\n",
      "============================================================\n",
      "=== Training InceptionV3 for Run 1 ===\n",
      "============================================================\n",
      "Loading existing model from: saved_models\\InceptionV3.keras\n",
      "Epoch 1/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - acc: 0.6343 - loss: 0.9136 - val_acc: 0.6821 - val_loss: 0.7934\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - acc: 0.6561 - loss: 0.8643 - val_acc: 0.6998 - val_loss: 0.7613\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - acc: 0.6709 - loss: 0.8195 - val_acc: 0.7006 - val_loss: 0.7877\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - acc: 0.6726 - loss: 0.8076 - val_acc: 0.6506 - val_loss: 0.8562\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - acc: 0.6922 - loss: 0.7704 - val_acc: 0.7013 - val_loss: 0.8109\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - acc: 0.6887 - loss: 0.7712 - val_acc: 0.7068 - val_loss: 0.7434\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - acc: 0.6960 - loss: 0.7525 - val_acc: 0.6891 - val_loss: 0.7648\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - acc: 0.6954 - loss: 0.7487 - val_acc: 0.7153 - val_loss: 0.7463\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - acc: 0.6902 - loss: 0.7568 - val_acc: 0.7006 - val_loss: 0.7678\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - acc: 0.7118 - loss: 0.7398 - val_acc: 0.7150 - val_loss: 0.7560\n",
      "Epoch 11/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - acc: 0.7018 - loss: 0.7441 - val_acc: 0.7043 - val_loss: 0.7462\n",
      "Epoch 12/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - acc: 0.7168 - loss: 0.7153 - val_acc: 0.7187 - val_loss: 0.7295\n",
      "Epoch 13/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - acc: 0.7139 - loss: 0.7312 - val_acc: 0.7150 - val_loss: 0.7336\n",
      "Epoch 14/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - acc: 0.6979 - loss: 0.7375 - val_acc: 0.7061 - val_loss: 0.7398\n",
      "Epoch 15/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - acc: 0.7104 - loss: 0.7129 - val_acc: 0.7146 - val_loss: 0.7309\n",
      "Epoch 16/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - acc: 0.7182 - loss: 0.7155 - val_acc: 0.6887 - val_loss: 0.7649\n",
      "Epoch 17/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - acc: 0.7226 - loss: 0.7028 - val_acc: 0.7272 - val_loss: 0.7278\n",
      "Epoch 18/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - acc: 0.7250 - loss: 0.6930 - val_acc: 0.6525 - val_loss: 0.8113\n",
      "Epoch 19/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - acc: 0.7088 - loss: 0.7093 - val_acc: 0.7017 - val_loss: 0.7634\n",
      "Epoch 20/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - acc: 0.7147 - loss: 0.7048 - val_acc: 0.7238 - val_loss: 0.7209\n",
      "Epoch 21/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - acc: 0.7305 - loss: 0.6819 - val_acc: 0.7201 - val_loss: 0.7245\n",
      "Epoch 22/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - acc: 0.7313 - loss: 0.6827 - val_acc: 0.7176 - val_loss: 0.7231\n",
      "Epoch 23/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - acc: 0.7224 - loss: 0.6781 - val_acc: 0.7176 - val_loss: 0.7591\n",
      "Epoch 24/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - acc: 0.7235 - loss: 0.6831 - val_acc: 0.7176 - val_loss: 0.7313\n",
      "Epoch 25/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - acc: 0.7248 - loss: 0.6848 - val_acc: 0.7083 - val_loss: 0.7667\n",
      "Epoch 26/50\n",
      "\u001b[1m20/99\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 1s/step - acc: 0.7403 - loss: 0.6664"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import InceptionV3, VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- 1. Global Configuration ---\n",
    "# Data and Model Paths\n",
    "source_dirs = {\n",
    "    \"sunny\": \"./data/sunny\", \"cloudy\": \"./data/cloudy\",\n",
    "    \"rainy\": \"./data/rainy\", \"snowy\": \"./data/snowy\", \"foggy\": \"./data/foggy\",\n",
    "}\n",
    "base_train_dir = Path(\"./data/weather_train\")\n",
    "base_valid_dir = Path(\"./data/weather_validation\")\n",
    "base_test_dir = Path(\"./data/weather_test\")\n",
    "SAVED_MODELS_DIR = Path(\"./saved_models\")\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "\n",
    "# Data and Training Hyperparameters\n",
    "train_pct, validation_pct, test_pct = 0.70, 0.15, 0.15\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 128\n",
    "NUM_TRAINING_RUNS = 5\n",
    "\n",
    "# --- 2. Setup Functions ---\n",
    "def setup_data_directories():\n",
    "    \"\"\"(Onetime) Cleans and creates the directory structure for train/val/test splits.\"\"\"\n",
    "    print(\"--- Setting up data directories ---\")\n",
    "    for base_dir in [base_train_dir, base_valid_dir, base_test_dir]:\n",
    "        if base_dir.exists(): shutil.rmtree(base_dir)\n",
    "        for weather_type in source_dirs.keys():\n",
    "            os.makedirs(base_dir / weather_type, exist_ok=True)\n",
    "    for weather_type, source_path_str in source_dirs.items():\n",
    "        source_path = Path(source_path_str)\n",
    "        if not source_path.exists(): continue\n",
    "        all_images = [f for f in os.listdir(source_path) if os.path.isfile(source_path / f)]\n",
    "        random.shuffle(all_images)\n",
    "        total_images = len(all_images)\n",
    "        train_amount = int(total_images * train_pct)\n",
    "        validation_amount = int(total_images * validation_pct)\n",
    "        train_split = all_images[:train_amount]\n",
    "        valid_split = all_images[train_amount : train_amount + validation_amount]\n",
    "        test_split = all_images[train_amount + validation_amount :]\n",
    "        for image in train_split: shutil.copyfile(source_path / image, base_train_dir / weather_type / image)\n",
    "        for image in valid_split: shutil.copyfile(source_path / image, base_valid_dir / weather_type / image)\n",
    "        for image in test_split: shutil.copyfile(source_path / image, base_test_dir / weather_type / image)\n",
    "    print(\"Data preparation complete.\\n\")\n",
    "\n",
    "# In create_data_generators()\n",
    "\n",
    "def create_data_generators():\n",
    "    \"\"\"Creates and returns train, validation, and test data generators.\"\"\"\n",
    "    # Add augmentation to the training generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "    )\n",
    "\n",
    "    # Validation and test generators should NOT be augmented, only rescaled.\n",
    "    valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    # ... rest of the function remains the same\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=base_train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        seed=63,\n",
    "    )\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        directory=base_valid_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        seed=63,\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=base_test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False,\n",
    "        seed=63,\n",
    "    )\n",
    "    return train_generator, valid_generator, test_generator\n",
    "\n",
    "# --- 3. Model Building Functions ---\n",
    "def create_custom_cnn(input_shape, num_classes):\n",
    "    \"\"\"Builds the custom CNN from scratch.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"), layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"), layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"), layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(), layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_transfer_model(base_model_fn, input_shape, num_classes):\n",
    "    \"\"\"Builds a transfer learning model with a given base.\"\"\"\n",
    "    conv_base = base_model_fn(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    conv_base.trainable = False\n",
    "    model = models.Sequential([\n",
    "        conv_base,\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# --- 4. Plotting and Evaluation Functions ---\n",
    "def save_history_plot(history, title, save_path):\n",
    "    \"\"\"Plots training/validation accuracy and loss, then saves the figure.\"\"\"\n",
    "    acc, val_acc = history.history[\"acc\"], history.history[\"val_acc\"]\n",
    "    loss, val_loss = history.history[\"loss\"], history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    ax1.plot(epochs, acc, \"bo\", label=\"Training acc\"); ax1.plot(epochs, val_acc, \"b\", label=\"Validation acc\"); ax1.set_title(\"Training and validation accuracy\"); ax1.legend()\n",
    "    ax2.plot(epochs, loss, \"bo\", label=\"Training loss\"); ax2.plot(epochs, val_loss, \"b\", label=\"Validation loss\"); ax2.set_title(\"Training and validation loss\"); ax2.legend()\n",
    "    plt.savefig(save_path); plt.close(fig)\n",
    "\n",
    "def evaluate_and_save_results(model, test_generator, run_dir):\n",
    "    \"\"\"Evaluates a single model, saves its individual reports, and returns its predictions.\"\"\"\n",
    "    print(f\"--- Generating individual report and saving results to: {run_dir} ---\")\n",
    "    y_pred_probs = model.predict(test_generator, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels)\n",
    "    report_path = run_dir / \"classification_report.txt\"\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"Classification Report for {run_dir.parent.name} - {run_dir.name}\\n\" + \"=\" * 50 + \"\\n\" + report)\n",
    "    print(f\"Individual classification report saved to {report_path}\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f\"Confusion Matrix - {run_dir.parent.name} ({run_dir.name})\"); plt.ylabel(\"True Label\"); plt.xlabel(\"Predicted Label\")\n",
    "    cm_path = run_dir / \"confusion_matrix.png\"\n",
    "    plt.savefig(cm_path); plt.close()\n",
    "    print(f\"Individual confusion matrix plot saved to {cm_path}\")\n",
    "    return y_pred\n",
    "\n",
    "def create_combined_confusion_matrix(predictions_dict, y_true, class_labels, run_number, save_dir):\n",
    "    \"\"\"Creates a single plot with 2x2 confusion matrices for all models.\"\"\"\n",
    "    print(\"\\n\" + \"-\" * 50 + f\"\\nGenerating Combined Confusion Matrix for Run {run_number}\\n\" + \"-\" * 50)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f\"Model Comparison: Confusion Matrices (Run {run_number})\", fontsize=20)\n",
    "    for i, (model_name, y_pred) in enumerate(predictions_dict.items()):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, ax=axes[i], annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "        axes[i].set_title(model_name); axes[i].set_ylabel(\"True Label\"); axes[i].set_xlabel(\"Predicted Label\")\n",
    "    save_path = save_dir / f\"Combined_Matrix_Run_{run_number}.png\"\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]); plt.savefig(save_path); plt.close(fig)\n",
    "    print(f\"Combined confusion matrix plot saved to {save_path}\")\n",
    "\n",
    "all_runs_results = {\n",
    "    \"Custom_CNN\": [], \"InceptionV3\": [], \"VGG16\": [], \"ResNet50\": []\n",
    "}\n",
    "\n",
    "# --- 5. Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # setup_data_directories()\n",
    "    SAVED_MODELS_DIR.mkdir(exist_ok=True); RESULTS_DIR.mkdir(exist_ok=True)\n",
    "    train_gen, valid_gen, test_gen = create_data_generators()\n",
    "    num_classes = len(train_gen.class_indices)\n",
    "    input_shape = IMG_SIZE + (3,)\n",
    "    y_true_labels = test_gen.classes\n",
    "    class_names = list(test_gen.class_indices.keys())\n",
    "\n",
    "    models_to_train = [\n",
    "        {\"name\": \"Custom_CNN\", \"builder\": create_custom_cnn, \"epochs\": 50, \"optimizer\": \"rmsprop\"},\n",
    "        {\"name\": \"InceptionV3\", \"builder\": lambda: create_transfer_model(InceptionV3, input_shape, num_classes), \"epochs\": 50, \"optimizer\": \"rmsprop\"},\n",
    "        {\"name\": \"VGG16\", \"builder\": lambda: create_transfer_model(VGG16, input_shape, num_classes), \"epochs\": 50, \"optimizer\": \"rmsprop\"},\n",
    "        {\"name\": \"ResNet50\", \"builder\": lambda: create_transfer_model(ResNet50, input_shape, num_classes), \"epochs\": 50, \"optimizer\": \"rmsprop\"},\n",
    "    ]\n",
    "\n",
    "    for run_number in range(1, NUM_TRAINING_RUNS + 1):\n",
    "        run_predictions = {}\n",
    "        print(\"\\n\" + \"#\" * 70 + f\"\\n### PROCESSING RUN {run_number}/{NUM_TRAINING_RUNS}\\n\" + \"#\" * 70)\n",
    "\n",
    "        for config in models_to_train:\n",
    "            model_name = config[\"name\"]\n",
    "            model_path = SAVED_MODELS_DIR / f\"{model_name}.keras\"\n",
    "            run_dir = RESULTS_DIR / model_name / f\"Run_{run_number}\"\n",
    "            print(\"\\n\" + \"=\" * 60 + f\"\\n=== Training {model_name} for Run {run_number} ===\\n\" + \"=\" * 60)\n",
    "            run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if model_path.exists():\n",
    "                print(f\"Loading existing model from: {model_path}\")\n",
    "                model = models.load_model(model_path)\n",
    "            else:\n",
    "                print(\"Creating a new model...\")\n",
    "                model = config[\"builder\"](input_shape, num_classes) if model_name == \"Custom_CNN\" else config[\"builder\"]()\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer=config[\"optimizer\"], metrics=[\"acc\"])\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n",
    "            history = model.fit(train_gen, epochs=config[\"epochs\"], validation_data=valid_gen, callbacks=[early_stopping])\n",
    "            print(f\"Saving model to: {model_path}\"); model.save(model_path)\n",
    "            history_plot_path = run_dir / \"training_history.png\"\n",
    "            save_history_plot(history, f\"{model_name} - Run {run_number}\", history_plot_path)\n",
    "            print(f\"Training history plot saved to {history_plot_path}\")\n",
    "            print(\"\\n--- Performing quick test evaluation ---\")\n",
    "            eval_test = model.evaluate(test_gen, verbose=0)\n",
    "            test_accuracy = eval_test[1]\n",
    "            print(f\"--> Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "            all_runs_results[model_name].append(test_accuracy)\n",
    "\n",
    "            y_pred = evaluate_and_save_results(model, test_gen, run_dir)\n",
    "            run_predictions[model_name] = y_pred\n",
    "\n",
    "        create_combined_confusion_matrix(run_predictions, y_true_labels, class_names, run_number, RESULTS_DIR)\n",
    "\n",
    "    print(\"\\n\\nAll training and evaluation cycles complete.\")\n",
    "    print(\"\\n\\n\" + \"=\" * 70)\n",
    "print(\"### AGGREGATE RESULTS ACROSS ALL RUNS ###\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_report = \"| Model         | Mean Test Accuracy | Std Deviation |\\n\"\n",
    "summary_report += \"|---------------|--------------------|---------------|\\n\"\n",
    "\n",
    "for model_name, accuracies in all_runs_results.items():\n",
    "    if accuracies:\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"  - Mean Test Accuracy: {mean_acc:.4f} ({mean_acc * 100:.2f}%)\")\n",
    "        print(f\"  - Std Deviation:      {std_acc:.4f}\")\n",
    "        summary_report += f\"| {model_name:<13} | {mean_acc:.4f}           | {std_acc:.4f}         |\\n\"\n",
    "\n",
    "# Save the summary report to a file\n",
    "summary_path = RESULTS_DIR / \"final_summary_report.md\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(f\"# Final Model Performance Summary ({NUM_TRAINING_RUNS} Runs)\\n\\n\")\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"\\nFinal summary report saved to {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
